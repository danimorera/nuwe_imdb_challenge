{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "train_titles = pd.read_csv(\"./data/train/train_titles.csv\")\n",
    "train_credits = pd.read_csv(\"./data/train/train_credits.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16545 entries, 0 to 16544\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   train_idx             16545 non-null  int64  \n",
      " 1   id                    16545 non-null  object \n",
      " 2   title                 16545 non-null  object \n",
      " 3   type                  16545 non-null  object \n",
      " 4   description           16512 non-null  object \n",
      " 5   release_year          16545 non-null  int64  \n",
      " 6   age_certification     8646 non-null   object \n",
      " 7   runtime               16545 non-null  int64  \n",
      " 8   genres                16545 non-null  object \n",
      " 9   production_countries  16545 non-null  object \n",
      " 10  seasons               4422 non-null   float64\n",
      " 11  streaming             16545 non-null  object \n",
      " 12  imdb_votes            16545 non-null  int64  \n",
      " 13  imdb_score            16545 non-null  float64\n",
      " 14  target                16545 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(8)\n",
      "memory usage: 1.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    4983\n",
       "6    4371\n",
       "4    3425\n",
       "3    1460\n",
       "7    1402\n",
       "2     633\n",
       "1     178\n",
       "8      65\n",
       "0      28\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of train_titles\n",
    "train_titles.head()\n",
    "\n",
    "# Display summary statistics of train_titles\n",
    "train_titles.info()\n",
    "\n",
    "# Check for missing values in train_titles and handle them if necessary\n",
    "train_titles.isnull().sum()\n",
    "\n",
    "# Explore the target variable 'target'\n",
    "train_titles['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X_train = train_titles.drop(['imdb_score', 'target'], axis=1)\n",
    "y_train = train_titles['target']\n",
    "\n",
    "# Choose a machine learning model (e.g., RandomForestClassifier)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using cross-validation (e.g., F1-score)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define the scoring metric\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "# Calculate the mean F1-score\n",
    "mean_f1_score = cv_scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_titles = pd.read_csv(\"test_titles.csv\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "X_test = test_titles.drop('id', axis=1)  # Assuming 'id' is not required for predictions\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_score_class(score):\n",
    "    # Function definition remains the same as provided in the challenge\n",
    "\n",
    "# Transform the predicted scores into target classes\n",
    "predicted_classes = [get_imdb_score_class(score) for score in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with test indexes as keys and predicted target classes as values\n",
    "predictions_dict = {\"target\": dict(zip(test_titles['id'], predicted_classes))}\n",
    "\n",
    "# Save the predictions in the specified format\n",
    "import json\n",
    "\n",
    "with open(\"predictions.json\", \"w\") as f:\n",
    "    json.dump(predictions_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
